{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lera_bert_reddit_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZIv5FJKIpBi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet\n",
        "!pip install praw --quiet\n",
        "!pip install torch torchvision --quiet\n",
        "\n",
        "from transformers import BertTokenizerFast, BertTokenizer, BertModel\n",
        "import praw\n",
        "from itertools import chain\n",
        "import torch"
      ],
      "metadata": {
        "id": "JbH-Kn0nvXhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03014721-812f-4f36-8153-3a363a85ccc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 37.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 188 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import logging\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "mKej7wwR0hRw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RedditUser:\n",
        "    def __init__(self, reddit: praw.Reddit, user_name):\n",
        "        self.user = reddit.redditor(user_name)\n",
        "\n",
        "    def fetch_texts(self, depth):\n",
        "        return chain(self._fetch_comments(depth), \n",
        "                     self._fetch_post(depth))\n",
        "\n",
        "    def _fetch_comments(self, depth):\n",
        "        return map(lambda c: c.body, \n",
        "                   self.user.comments.new(limit=depth))\n",
        "\n",
        "    def _fetch_post(self, depth):\n",
        "        return map(lambda s: s.selftext, \n",
        "                   self.user.submissions.new(limit=depth))\n",
        "\n",
        "\n",
        "class RedditAuth:\n",
        "  def __init__(self, client_id, client_secret, user_agent):\n",
        "    self.client_id = client_id\n",
        "    self.client_secret = client_secret\n",
        "    self.user_agent = user_agent\n",
        "\n",
        "\n",
        "class Reddit:\n",
        "  def __init__(self, text_fetch_depth, reddit_auth):\n",
        "    self.text_fetch_depth = text_fetch_depth\n",
        "    self.reddit = praw.Reddit(\n",
        "      client_id=reddit_auth.client_id,\n",
        "      client_secret=reddit_auth.client_secret,\n",
        "      user_agent=reddit_auth.user_agent,\n",
        "      check_for_async=False) # to supress some strange warnings\n",
        "    \n",
        "  def user_texts(self, user_name):\n",
        "    return RedditUser(self.reddit, user_name).fetch_texts(self.text_fetch_depth)"
      ],
      "metadata": {
        "id": "kLprGEfDCgeJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextToVecUsingHiddenState:\n",
        "  def __init__(self, max_length) -> None:\n",
        "      self.max_length = max_length\n",
        "      self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "      self.bert_encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "  def _hidden_state(self, last_hidden_state):\n",
        "    return torch.mean(torch.squeeze(last_hidden_state), dim=0)\n",
        "\n",
        "  def __call__(self, text):\n",
        "      tokens = self.tokenizer.encode_plus(text, return_tensors='pt', \n",
        "                             max_length=self.max_length, \n",
        "                             truncation=True)\n",
        "      encoded = self.bert_encoder(**tokens)\n",
        "      return self._hidden_state(encoded.last_hidden_state)"
      ],
      "metadata": {
        "id": "7Lo5H8WULZkd"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextToVecUsingPoolerOutput:\n",
        "  def __init__(self, max_length) -> None:\n",
        "      self.max_length = max_length\n",
        "      self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "      self.feature_extractor = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "  def __call__(self, text):\n",
        "      token = self.tokenizer.encode_plus(text, return_tensors='pt', \n",
        "                             max_length=self.max_length, \n",
        "                             truncation=True)\n",
        "      result = self.feature_extractor(**token)\n",
        "      return result.pooler_output.flatten()"
      ],
      "metadata": {
        "id": "JGFZ1qv0f3XJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Application:\n",
        "  def __init__(self, \n",
        "               text_to_vec,\n",
        "               text_fetch_depth, \n",
        "               reddit_auth):\n",
        "      self.reddit = Reddit(text_fetch_depth, reddit_auth)\n",
        "      self.text_to_vec = text_to_vec\n",
        "\n",
        "  def _mean(self, list_of_text_vec):\n",
        "      matrix_of_text_vectors = torch.stack(list_of_text_vec, dim=0)\n",
        "      return torch.mean(matrix_of_text_vectors, dim=0)\n",
        "  \n",
        "  def _calculate_similarity_score(self, user_name_1, user_name_2):\n",
        "    list_of_text_vec_1 = list(map(self.text_to_vec, \n",
        "                                  self.reddit.user_texts(user_name_1)))\n",
        "    vec_1 = self._mean(list_of_text_vec_1)\n",
        "\n",
        "    list_of_text_vec_2 = list(map(self.text_to_vec, \n",
        "                                  self.reddit.user_texts(user_name_2)))\n",
        "    vec_2 = self._mean(list_of_text_vec_2)\n",
        "    return torch.dot(vec_1, vec_2) / (vec_1.norm() * vec_2.norm())\n",
        "\n",
        "  @staticmethod\n",
        "  def main_loop(text_to_vec, text_fetch_depth, reddit_auth):\n",
        "    app = Application(text_to_vec, text_fetch_depth, reddit_auth)\n",
        "\n",
        "    while True:\n",
        "      user_name_1 = input('Please enter first user name: ')\n",
        "      user_name_2 = input('Please enter second user name: ')\n",
        "      print(f'''The similarity score between {user_name_1} and {user_name_2}\n",
        "             is {app._calculate_similarity_score(user_name_1, user_name_2)}''')"
      ],
      "metadata": {
        "id": "S1R5TLnacAt2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_auth = RedditAuth(client_id=\"lHtve-vYh8mpZ6DbTH450A\",\n",
        "                         client_secret=\"KZOKIAL944VQabOWqGni7jEJscssMg\",\n",
        "                         user_agent=\"android:com.example.test:v1.2.3 (by u/kemitcheProfessionalInside45)\")\n",
        "\n",
        "text_fetch_depth = 35\n",
        "max_tokenizer_length = 300\n",
        "text_to_vec = TextToVecUsingHiddenState(max_tokenizer_length) # choose one of two implementations\n",
        "\n",
        "Application.main_loop(text_to_vec, text_fetch_depth, reddit_auth)"
      ],
      "metadata": {
        "id": "AaaL393PfC30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user name examples\n",
        "'xtilexx'\n",
        "'Sir_Loinbeef'\n",
        "'Repulsive_Love_'\n",
        "'ForecastForFourCats'"
      ],
      "metadata": {
        "id": "GAnH6IePvxLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KWbcb72v_AtH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
